#!/usr/bin/env python
"""
Policy í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
ì‹œë®¬ë ˆì´ì…˜ ë˜ëŠ” ì‹¤ì œ ë¡œë´‡ì—ì„œ í…ŒìŠ¤íŠ¸
"""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

import torch
from policy import SimplePolicy
from simulation import SimpleSimEnv


def evaluate_in_sim():
    """ì‹œë®¬ë ˆì´ì…˜ì—ì„œ í‰ê°€"""

    # ========================================================================
    # ì„¤ì •
    # ========================================================================
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
    PROJECT_ROOT = Path(__file__).parent.parent
    MODEL_PATH = PROJECT_ROOT / "examples" / "models" / "best_policy.pth"
    NUM_EPISODES = 10
    RENDER = True

    if not MODEL_PATH.exists():
        print(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {MODEL_PATH}")
        print(f"   ë¨¼ì € í•™ìŠµí•˜ì„¸ìš”: python scripts/train_policy.py")
        return

    print("\n" + "="*70)
    print("  Policy í‰ê°€ (ì‹œë®¬ë ˆì´ì…˜)")
    print("="*70)
    print(f"  ëª¨ë¸: {MODEL_PATH}")
    print(f"  ì—í”¼ì†Œë“œ: {NUM_EPISODES}")
    print("="*70 + "\n")

    # ========================================================================
    # ëª¨ë¸ ë¡œë“œ
    # ========================================================================
    print("ğŸ§  ëª¨ë¸ ë¡œë“œ ì¤‘...")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = SimplePolicy.load(str(MODEL_PATH))
    model = model.to(device)
    model.eval()

    print(f"   ë””ë°”ì´ìŠ¤: {device}\n")

    # ========================================================================
    # í™˜ê²½ ì´ˆê¸°í™”
    # ========================================================================
    env = SimpleSimEnv(num_joints=6, max_steps=200)

    # ========================================================================
    # í‰ê°€ ë£¨í”„
    # ========================================================================
    print("ğŸ® í‰ê°€ ì‹œì‘...\n")

    successes = 0
    total_rewards = []

    for episode in range(NUM_EPISODES):
        obs = env.reset(randomize=True)
        done = False
        episode_reward = 0
        step = 0

        while not done:
            # Policyë¡œ ì•¡ì…˜ ì˜ˆì¸¡
            action = model.predict(obs)

            # í™˜ê²½ ìŠ¤í…
            obs, reward, done, info = env.step(action)

            episode_reward += reward
            step += 1

        # ê²°ê³¼
        success = info['success']
        if success:
            successes += 1

        total_rewards.append(episode_reward)

        status = "âœ… ì„±ê³µ" if success else "âŒ ì‹¤íŒ¨"
        print(f"Episode {episode+1:2d}/{NUM_EPISODES} | "
              f"{status} | "
              f"Steps: {step:3d} | "
              f"Reward: {episode_reward:6.2f} | "
              f"Distance: {info['distance']:.2f}")

        # ë§ˆì§€ë§‰ ì—í”¼ì†Œë“œ ë Œë”ë§
        if RENDER and episode == NUM_EPISODES - 1:
            save_path = Path.home() / "robot_results" / "last_episode.png"
            save_path.parent.mkdir(exist_ok=True)
            env.render(save_path=str(save_path))

    # ========================================================================
    # í†µê³„
    # ========================================================================
    success_rate = successes / NUM_EPISODES * 100
    avg_reward = sum(total_rewards) / len(total_rewards)

    print("\n" + "="*70)
    print("  ğŸ“Š í‰ê°€ ê²°ê³¼")
    print("="*70)
    print(f"   ì„±ê³µë¥ : {success_rate:.1f}% ({successes}/{NUM_EPISODES})")
    print(f"   í‰ê·  ë³´ìƒ: {avg_reward:.2f}")
    print("="*70 + "\n")


def evaluate_on_robot():
    """ì‹¤ì œ ë¡œë´‡ì—ì„œ í‰ê°€"""

    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
    PROJECT_ROOT = Path(__file__).parent.parent
    MODEL_PATH = PROJECT_ROOT / "examples" / "models" / "best_policy.pth"
    ROBOT_PORT = "/dev/ttyUSB0"
    MOTOR_MODEL = "ax-12a"

    if not MODEL_PATH.exists():
        print(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {MODEL_PATH}")
        return

    print("\n" + "="*70)
    print("  Policy í‰ê°€ (ì‹¤ì œ ë¡œë´‡)")
    print("="*70)
    print(f"  ëª¨ë¸: {MODEL_PATH}")
    print(f"  ë¡œë´‡: {ROBOT_PORT}")
    print("="*70 + "\n")

    # ëª¨ë¸ ë¡œë“œ
    from policy import SimplePolicy
    model = SimplePolicy.load(str(MODEL_PATH))
    model.eval()

    # ë¡œë´‡ ì—°ê²°
    from robots import SimpleRobot
    robot = SimpleRobot(
        port=ROBOT_PORT,
        motor_model=MOTOR_MODEL,
        robot_id="eval_robot",
    )

    try:
        robot.connect()

        print("\nğŸ¤– ë¡œë´‡ìœ¼ë¡œ Policy ì‹¤í–‰ ì¤‘...")
        print("   Ctrl+Cë¡œ ì¢…ë£Œ\n")

        import time

        while True:
            # í˜„ì¬ ìƒíƒœ ì½ê¸°
            obs = robot.get_observation()

            # Policyë¡œ ì•¡ì…˜ ì˜ˆì¸¡
            action = model.predict(obs)

            # ë¡œë´‡ì— ì „ì†¡
            robot.send_action(action)

            time.sleep(0.033)  # 30Hz

    except KeyboardInterrupt:
        print("\n\nâ¸ï¸  ì¢…ë£Œë¨")

    finally:
        robot.disconnect()


if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == "robot":
        # ì‹¤ì œ ë¡œë´‡ í‰ê°€
        evaluate_on_robot()
    else:
        # ì‹œë®¬ë ˆì´ì…˜ í‰ê°€ (ê¸°ë³¸)
        evaluate_in_sim()
